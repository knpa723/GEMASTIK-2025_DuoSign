{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd024822",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========== PARAMETER ==========\n",
    "RAW_FOLDER = '/kaggle/input/data-gemastik-cv-sementara'         # Folder gambar seperti \"Saja_16.jpg\"\n",
    "CROPPED_FOLDER = 'cropped_dataset' # Folder hasil crop tangan\n",
    "IMAGE_SIZE = (1920, 1080)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# ========== 1. Mediapie ==========\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "def draw_landmarks_only_pose_and_hands(image, results):\n",
    "    annotated = image.copy()\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "        )\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated,\n",
    "            results.left_hand_landmarks,\n",
    "            mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2)\n",
    "        )\n",
    "\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated,\n",
    "            results.right_hand_landmarks,\n",
    "            mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2)\n",
    "        )\n",
    "\n",
    "    return annotated\n",
    "\n",
    "def extract_and_save(img_path, output_base):\n",
    "    filename = os.path.basename(img_path)\n",
    "\n",
    "    # Lewati file yang tidak mengandung underscore\n",
    "    if \"_\" not in filename:\n",
    "        print(f\"‚ùå Skip (tidak ada underscore): {filename}\")\n",
    "        return False\n",
    "\n",
    "    class_name = filename.split(\"_\")[0]\n",
    "    output_dir = os.path.join(output_base, class_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"‚ùå Gagal baca gambar: {img_path}\")\n",
    "        return False\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Jalankan MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=0,\n",
    "        refine_face_landmarks=False\n",
    "    ) as holistic:\n",
    "        result = holistic.process(img_rgb)\n",
    "\n",
    "        if result.pose_landmarks or result.left_hand_landmarks or result.right_hand_landmarks:\n",
    "            annotated = draw_landmarks_only_pose_and_hands(img, result)\n",
    "            annotated = cv2.resize(annotated, IMAGE_SIZE)\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(output_path, annotated)\n",
    "            print(f\"‚úÖ {filename} ‚Üí {class_name}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Tidak ada landmark terdeteksi: {filename}\")\n",
    "            return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üì¶ Memproses gambar dengan MediaPipe...\")\n",
    "    os.makedirs(CROPPED_FOLDER, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(RAW_FOLDER):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            full_path = os.path.join(RAW_FOLDER, file)\n",
    "            extract_and_save(full_path, CROPPED_FOLDER)\n",
    "\n",
    "\n",
    "# ========== 2. Data Generator ==========\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    CROPPED_FOLDER,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    CROPPED_FOLDER,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(train_gen.class_indices)\n",
    "\n",
    "# ========== Cek Data ==========\n",
    "# Ambil satu batch dari generator\n",
    "train_img_batch, train_label_batch = next(train_gen)\n",
    "val_img_batch, val_label_batch = next(val_gen)  # Atau val_gen, tergantung nama kamu\n",
    "\n",
    "# Ambil gambar pertama dari batch\n",
    "train_img = train_img_batch[0]\n",
    "train_label_idx = np.argmax(train_label_batch[0])\n",
    "train_label = list(train_gen.class_indices.keys())[train_label_idx]\n",
    "\n",
    "val_img = val_img_batch[0]\n",
    "val_label_idx = np.argmax(val_label_batch[0])\n",
    "val_label = list(val_gen.class_indices.keys())[val_label_idx]\n",
    "\n",
    "# Tampilkan gambar train\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(train_img)\n",
    "plt.title(f\"[TRAIN] Label: {train_label}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Tampilkan gambar val\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(val_img)\n",
    "plt.title(f\"[val] Label: {val_label}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ========== 3. Model MobileNet ==========\n",
    "base_model = MobileNetV2(input_shape=IMAGE_SIZE + (3,), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ========== 4. Training ==========\n",
    "print(\"üöÄ Training dimulai...\")\n",
    "early_stop = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ========== 5. Simpan Model ==========\n",
    "model.save(\"mobilenet_gesture_model.h5\")\n",
    "print(\"‚úÖ Model tersimpan sebagai mobilenet_gesture_model.h5\")\n",
    "\n",
    "# ========== 6. Evaluasi ==========\n",
    "loss, acc = model.evaluate(val_gen)\n",
    "print(f\"üéØ Akurasi Validasi: {acc:.2%}\")\n",
    "\n",
    "# ========== 7. Inference ==========\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Muat ulang model\n",
    "model = load_model(\"mobilenet_gesture_model.h5\")\n",
    "\n",
    "# Pilih salah satu gambar dari folder CROPPED_FOLDER\n",
    "sample_class = np.random.choice(os.listdir(CROPPED_FOLDER))\n",
    "sample_img_path = os.path.join(CROPPED_FOLDER, sample_class, np.random.choice(os.listdir(os.path.join(CROPPED_FOLDER, sample_class))))\n",
    "\n",
    "# Baca dan preprocess\n",
    "img = cv2.imread(sample_img_path)\n",
    "img_resized = cv2.resize(img, IMAGE_SIZE)\n",
    "img_normalized = img_resized / 255.0\n",
    "img_input = np.expand_dims(img_normalized, axis=0)\n",
    "\n",
    "# Prediksi\n",
    "pred = model.predict(img_input)[0]\n",
    "pred_idx = np.argmax(pred)\n",
    "pred_label = list(train_gen.class_indices.keys())[pred_idx]\n",
    "\n",
    "# Tampilkan\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Prediksi: {pred_label} ({pred[pred_idx]:.2%})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
